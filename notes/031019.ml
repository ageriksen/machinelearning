
//////////////////
fig. 2.11, Hastie et al
    - func of complexity
    - MSE vs complexity
    - in regards to interpreting data
    - similar fig should be in report

    - also bias/variance graph
//////////////////

//// last week ////
Neural networks -> Feed forward nn
& back propagation algorithm + gradient descent

input layer, hidden layer 1-> (l-1), hidden layer l, 
hidden layer (l+1) etc., hidden layer (L-1), output layer L

each layer l_i activation func f, 
    f(z_i^l) = a_i^l } output
  & z_i^l = sum( w_ij^l a_j^(l-1) ) + b_i^l


    optimizw cost func for w and b


Regression: 
   cost func:
    C(w, b) = 0.5 sum_i(t_i - y_i)^2

        t_i target
        y_i output
output layer L
    y_i = a_i^L
    dC/dw_jk^L

Sigmoid


similarities for clasification - regarding derivation

quick reminder logistic regression
    [log-reg]
        &
    binary case

Cost func C(beta) see notes from 190919

looking at NeuralNet.ipynb
    multiclass classification
    MNIST dataset

    one-hot vector
    softmax function
    
